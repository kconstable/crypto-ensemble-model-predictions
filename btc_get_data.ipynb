{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "btc_get_data.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "xmS9SCGA7Njg",
        "NE7hUBxs7Xbp",
        "gFw85eTcwG_B",
        "uZh9mrbdeznE"
      ],
      "authorship_tag": "ABX9TyNwTB3+rBk8VsEw1r5wPISj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kconstable/crypto-ensemble-model-predictions/blob/main/btc_get_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05Db9gJTaW3Z"
      },
      "source": [
        "## Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8s4rGYBeOBz"
      },
      "source": [
        "# !pip install pygooglenews\n",
        "!pip install pytrends"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyAbdzpLiOgu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31ccb732-a0ee-4cbc-803d-29dd9af9210b"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import time\n",
        "import pickle\n",
        "import re\n",
        "from datetime import date, timedelta,datetime\n",
        "from tabulate import tabulate\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.express as px\n",
        "from google.colab import files\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.feature_selection import RFE\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# from pygooglenews import GoogleNews\n",
        "from pytrends.request import TrendReq\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import requests as req\n",
        "\n",
        "\n",
        "# alphavalue key\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/capstone2/data/av_key.txt') as f:\n",
        "    key = f.read().strip()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIj2bLyZMBCc"
      },
      "source": [
        "## Structured Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmS9SCGA7Njg"
      },
      "source": [
        "### Fundamentals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYt09HlUtMXg"
      },
      "source": [
        "stock = 'VMW'\n",
        "# current ratios\n",
        "url = f'https://www.alphavantage.co/query?function=OVERVIEW&symbol={stock}&apikey={key}'\n",
        "r = requests.get(url)\n",
        "data = r.json()\n",
        "\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tLTs49quVKg"
      },
      "source": [
        "url = f'https://www.alphavantage.co/query?function=EARNINGS&symbol={stock}&apikey={key}'\n",
        "r = requests.get(url)\n",
        "data = r.json()\n",
        "\n",
        "# Earnings Per Share\n",
        "print('date\\t Reported EPS\\t Estimated EPS\\t Surprise %')\n",
        "for earnings in data['quarterlyEarnings']:\n",
        "  print(f\"{earnings['reportedDate']}\\t {earnings['reportedEPS']}\\t {earnings['estimatedEPS']}\\t\\t {earnings['surprisePercentage']}\")\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQqC2UvNxFfN"
      },
      "source": [
        "# income\n",
        "stock= 'VMW'\n",
        "url = f'https://www.alphavantage.co/query?function=INCOME_STATEMENT&symbol={stock}&apikey={key}'\n",
        "r = requests.get(url)\n",
        "data = r.json()\n",
        "\n",
        "print('date\\t\\t Net Income\\t Gross Profit')\n",
        "for income in data['quarterlyReports']:\n",
        "  print(f\"{income['fiscalDateEnding']}\\t {income['comprehensiveIncomeNetOfTax']} \\t{income['grossProfit']}\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8dt1oHB-jMs"
      },
      "source": [
        "# cashflow\n",
        "url = f'https://www.alphavantage.co/query?function=CASH_FLOW&symbol={stock}&apikey={key}'\n",
        "r = requests.get(url)\n",
        "data = r.json()\n",
        "\n",
        "print('date\\t\\t ProfitLoss\\t Cashflow')\n",
        "for cf in data['quarterlyReports']:\n",
        "  print(f\"{cf['fiscalDateEnding']}\\t {cf['profitLoss']}\\t {cf['operatingCashflow']}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NE7hUBxs7Xbp"
      },
      "source": [
        "### Economic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruH4JM5H6C2X"
      },
      "source": [
        "def get_economic_indicators(funct,key,interval=None,maturity=None,throttle=0):\n",
        "  \"\"\"\n",
        "  Returns Economic Indicator Data with missing values interpolated between dates\n",
        "  Monthly Data:\n",
        "    NONFARM_PAYROLL, INFLATION_EXPECTATION,CONSUMER_SENTIMENT,UNEMPLOYMENT\n",
        "  Quarterly Data: \n",
        "    GDP\n",
        "  Daily Data:  \n",
        "    FEDERAL_FUNDS_RATE = interval (daily,weekly,monthly)\n",
        "    TREASURY_YIELD = interval (daily, weekly, monthly), \n",
        "                     maturity (3month, 5year, 10year, and 30year)\n",
        "  \"\"\"\n",
        "  \n",
        "  # query strings\n",
        "  # Monthly Data:\n",
        "  if funct in ['NONFARM_PAYROLL','INFLATION_EXPECTATION','CONSUMER_SENTIMENT','UNEMPLOYMENT']:\n",
        "    url = f'https://www.alphavantage.co/query?function={funct}&apikey={key}'\n",
        "\n",
        "\n",
        "  # Daily, Weekly,Monthly or Quarterly Data:\n",
        "  # Interest Rates\n",
        "  if funct in ['FEDERAL_FUNDS_RATE','REAL_GDP']:\n",
        "    url = f'https://www.alphavantage.co/query?function={funct}&interval={interval}&apikey={key}'\n",
        "\n",
        "  # Treasury Yield  \n",
        "  if funct == 'TREASURY_YIELD':\n",
        "    url = f'https://www.alphavantage.co/query?function={funct}&interval={interval}&maturity={maturity}&apikey={key}'\n",
        "\n",
        "  # pull data\n",
        "  r = requests.get(url)\n",
        "  time.sleep(throttle)\n",
        "  d = r.json()\n",
        "\n",
        "  # convert to df\n",
        "  df = pd.DataFrame(d['data'])\n",
        "\n",
        "  # move date to a datetime index\n",
        "  df.date = pd.to_datetime(df.date)\n",
        "  df.set_index('date',inplace=True)\n",
        "\n",
        "  # add the ticker name and frequency\n",
        "  df['name'] = d['name']\n",
        "  df['interval']=d['interval'] \n",
        "\n",
        "  # clean data & interpolate missing values\n",
        "  # missing data encoded with '.'\n",
        "  # change datatype to float\n",
        "  df.replace('.',np.nan,inplace=True)\n",
        "  df.value = df.value.astype('float')\n",
        "\n",
        "  # missing data stats\n",
        "  missing =sum(df.value.isna())\n",
        "  total =df.shape[0]\n",
        "  missing_pct = round(missing/total*100,2)\n",
        "\n",
        "  # interpolate using the time index\n",
        "  if missing >0:\n",
        "    df.value.interpolate(method='time',inplace=True)\n",
        "    action = 'interpolate-missing'\n",
        "  else:\n",
        "    action = 'none'\n",
        "\n",
        "  # Print the results\n",
        "  if maturity is not None:\n",
        "    summary = ['Economic Indicator',funct+':'+maturity,str(total),str(missing),str(missing_pct)+'%',action]\n",
        "  else:\n",
        "    summary = ['Economic Indicator',funct,str(total),str(missing),str(missing_pct)+'%',action]\n",
        "\n",
        "  return {'summary':summary,'data':df}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFw85eTcwG_B"
      },
      "source": [
        "### Commodities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNZy2P8gCRIf"
      },
      "source": [
        "def get_fx_rates(fx_from, fx_to,key,size='full',throttle=0):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  # query string\n",
        "  url = f'https://www.alphavantage.co/query?function=FX_DAILY&from_symbol={fx_from}&to_symbol={fx_to}&apikey={key}&outputsize={size}'\n",
        "  r = requests.get(url)\n",
        "\n",
        "  if r.status_code == 200:\n",
        "    data = r.json()\n",
        "    df = pd.DataFrame(data['Time Series FX (Daily)']).T\n",
        "    df.columns = ['open','high','low','close']\n",
        "    df = df[['close']]\n",
        "    \n",
        "    # change data types\n",
        "    df.index = pd.to_datetime(df.index)\n",
        "    df.close = df.close.astype('float')\n",
        "\n",
        "    # Calculate missing data\n",
        "    missing = sum(df.close.isna())\n",
        "    total = df.shape[0]\n",
        "    missing_pct = round(missing/total*100,2)\n",
        "\n",
        "    # rename the close column\n",
        "    df.columns = [f\"{fx_from}{fx_to}\"]\n",
        "\n",
        "    # Print the results\n",
        "    summary = ['Ticker',f'{fx_from}/{fx_to}',str(total),str(missing),str(missing_pct)+'%','none']\n",
        "\n",
        "  else:\n",
        "    summary = ['FX Rates',f'{fx_from}/{fx_to}','Requst Error','all','100%','none']\n",
        "    df = pd.DataFrame()\n",
        "  \n",
        "  return  {'summary':summary,'data':df}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGt4G7-ywHgF"
      },
      "source": [
        "def get_ticker_data(symbol,key,outputsize='compact',throttle=0):\n",
        "  \"\"\"\n",
        "  Returns daily data for a stock (symbol)\n",
        "    outputsize: compact(last 100) or full (20 years)\n",
        "    key: apikey\n",
        "    symbols: OILK (oil ETF),BAR(gold ETF),VXZ (volatility ETF)\n",
        "  \"\"\"\n",
        "  time.sleep(throttle)\n",
        "  url = f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={symbol}&outputsize={outputsize}&apikey={key}'\n",
        "  r = requests.get(url)\n",
        "  d = r.json()\n",
        "\n",
        "  # extract data to a df\n",
        "  df = pd.DataFrame(d['Time Series (Daily)']).T\n",
        "  df.columns = ['open','high','low','close','volume']\n",
        "  df['symbol'] = d['Meta Data']['2. Symbol']\n",
        "\n",
        "  # change data types\n",
        "  df.index = pd.to_datetime(df.index)\n",
        "\n",
        "  # convert datatype to float\n",
        "  for col in ['open','high','low','close','volume']:\n",
        "    df[col] = df[col].astype('float')\n",
        "\n",
        "  # Calculate missing data\n",
        "  missing = sum(df.close.isna())\n",
        "  total = df.shape[0]\n",
        "  missing_pct = round(missing/total*100,2)\n",
        "\n",
        "  # Print the results\n",
        "  summary = ['Ticker',symbol,str(total),str(missing),str(missing_pct)+'%','none']\n",
        "\n",
        "  return {'summary':summary,'data':df}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZh9mrbdeznE"
      },
      "source": [
        "### Technicals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2S1Qxixe2Oy"
      },
      "source": [
        "def calc_bollinger(df,feature,window=20,st=2):\n",
        "  \"\"\"\n",
        "  Calculates bollinger bands for a price time-series.  Used for crypto currencies\n",
        "  Input: \n",
        "    df     : A dataframe of time-series prices\n",
        "    feature: The name of the feature in the df to calculate the bands for\n",
        "    window : The size of the rolling window.  Defaults to 20 days with is standard\n",
        "    st     : The number of standard deviations to use in the calculation. 2 is standard \n",
        "  Output: \n",
        "    Returns the df with the bollinger band columns added\n",
        "  \"\"\"\n",
        "  # get the feature name\n",
        "  if feature != 'close':\n",
        "    name_u = f'b-upper-{feature}'\n",
        "    name_l = f'b-lower-{feature}'\n",
        "    name_m = f'b-middle-{feature}'\n",
        "  else:\n",
        "    name_u = 'b-upper'\n",
        "    name_l = 'b-lower'\n",
        "    name_m = 'b-middle'\n",
        "\n",
        "  # rolling mean and stdev\n",
        "  rolling_m  = df[feature].rolling(window).mean()\n",
        "  rolling_st = df[feature].rolling(window).std()\n",
        "\n",
        "  # add the upper/lower and middle bollinger bands\n",
        "  df[name_u]  = rolling_m + (rolling_st * st)\n",
        "  df[name_m] = rolling_m \n",
        "  df[name_l]  = rolling_m - (rolling_st * st)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rk8xg7ze58N"
      },
      "source": [
        "def calc_rsi(df,feature='close',window=14):\n",
        "  \"\"\"\n",
        "  Calculates the RSI for the input feature\n",
        "  Input:\n",
        "    df      : A dataframe with a time-series of prices\n",
        "    feature : The name of the feature in the df to calculate the bands for\n",
        "    window  : The size of the rolling window.  Defaults to 14 days which is standard\n",
        "  Output: \n",
        "    Returns the df with the rsi band column added\n",
        "  \"\"\"\n",
        "  # RSI\n",
        "  # calc the diff in daily prices, exclude nan\n",
        "  diff =df[feature].diff()\n",
        "  diff.dropna(how='any',inplace=True)\n",
        "\n",
        "  # separate positive and negitive changes\n",
        "  pos_m, neg_m = diff.copy(),diff.copy()\n",
        "  pos_m[pos_m<0]=0\n",
        "  neg_m[neg_m>0]=0\n",
        "\n",
        "  # positive/negative rolling means\n",
        "  prm = pos_m.rolling(window).mean()\n",
        "  nrm = neg_m.abs().rolling(window).mean()\n",
        "\n",
        "  # calc the rsi and add to the df\n",
        "  ratio = prm /nrm\n",
        "  rsi = 100.0 - (100.0 / (1.0 + ratio))\n",
        "  df['rsi']=rsi"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8iwxe5Qe9G3"
      },
      "source": [
        "def calc_macd(df,long=26,short=12,ma=9,feature='close'):\n",
        "  \"\"\"\n",
        "  Calculates the MACD and signial for the input feature\n",
        "  Input:\n",
        "    df      : A dataframe with a time-series of prices\n",
        "    feature : The name of the feature in the df to calculate the bands for\n",
        "  Output: \n",
        "    Returns the df with the macd columns added\n",
        "  \"\"\"\n",
        "  ema12 = df[feature].ewm(span=short,adjust=False).mean()\n",
        "  ema26 = df[feature].ewm(span=long,adjust=False).mean()\n",
        "  df['macd']=ema12-ema26\n",
        "  df['macd_signal'] = df['macd'].ewm(span=ma,adjust=False).mean()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4l_lZSff3cA"
      },
      "source": [
        "def calc_stoch_ossilator(df,window=14,feature = 'close'):\n",
        "  \"\"\"\n",
        "  Calculates the stochastic ossilator signal for the input feature\n",
        "  Params:\n",
        "    df: dataframe of prices\n",
        "    window: window lenght for high/low\n",
        "    feature: open, high,low,close\n",
        "  Reference:\n",
        "    https://www.learnpythonwithrune.org/pandas-calculate-the-stochastic-oscillator-indicator-for-stocks/\n",
        "  \"\"\"\n",
        "\n",
        "  # high/low values in the period\n",
        "  df['stoch_high'] = df[feature].rolling(window).max()\n",
        "  df['stoch_low']= df[feature].rolling(window).min()\n",
        "\n",
        "  df['stoch_K'] = (df[feature] - df['stoch_low'])*100/(df['stoch_high'] - df['stoch_low'])\n",
        "  df['stoch_D'] = df['stoch_K'].rolling(3).mean()\n",
        "\n",
        "  return df"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTLtPuZcf5H9"
      },
      "source": [
        "def plot_technicals(df,yearfrom=None):\n",
        "  \"\"\"\n",
        "  Plots technical indicators\n",
        "  Input:\n",
        "    df: a dataframe with techical indicators\n",
        "    yearfrom: filters the df by year\n",
        "  \"\"\"\n",
        "\n",
        "  # get the symbol name\n",
        "  name = df.ticker.unique()[0]\n",
        "\n",
        "  # filter by year if provided\n",
        "  if yearfrom is not None:\n",
        "    df = df[df.index.year >= yearfrom]\n",
        "\n",
        "\n",
        "  # make subplots\n",
        "  fig = make_subplots(rows=2, cols=2,\n",
        "                      shared_xaxes=True,\n",
        "                      subplot_titles = ('Bollinger Bands','MACD','Stochastic Oscillator','RSI'),\n",
        "                      vertical_spacing = 0.07)\n",
        "\n",
        "  # boolinger bands\n",
        "  # ********************************************************************************************\n",
        "  fig.add_trace(go.Scatter(x=df.index,y=df['b-upper'],name='Bollinger-Upper',line_color=\"#DFEBF9\"),row=1,col=1)\n",
        "  fig.add_trace(go.Scatter(x=df.index,y=df['b-lower'],name='Bollinger-Lower',line_color='#DFEBF9',fill='tonexty'),row=1,col=1)\n",
        "  fig.add_trace(go.Scatter(x=df.index,y=df.close,name='Closing Price',line_color='#a8b8d0'),row=1,col=1)\n",
        "\n",
        "\n",
        "  # MACD\n",
        "  # ********************************************************************************************\n",
        "  fig.add_trace(go.Scatter(x=df.index,y=df['macd'],name='MACD',line_color='#F7DAC6'),row=1,col=2)\n",
        "  fig.add_trace(go.Scatter(x=df.index,y=df['macd_signal'],name='MACD Signal',line_color='#E68A4C'),row=1,col=2)\n",
        "  try:\n",
        "    fig.add_trace(go.Bar(x=dff.index,y=df['macd_hist'],name='MACD Hist',marker_color='#E06D1F', marker_line_color='#E06D1F'),row=1,col=2)\n",
        "  except:\n",
        "    # skip mcad histogram for crypto\n",
        "    print('')\n",
        "\n",
        "  # Interest Rates\n",
        "  # add Fed Rate, then loop through the df columns to add any feature that is a yield\n",
        "  # ********************************************************************************************\n",
        "  # fig.add_trace(go.Scatter(x=df.index, y=df.ir,name='Fed Funds Rate',line_color='#4B9D0C'),row=2,col=1)\n",
        "  # colors = ['#0E340F','#29541F','#5E9C53','#A3E090','#537455','#3B463E']\n",
        "  # rate_cols = [c for c in df.columns if 'yield' in c]\n",
        "  # for i,rate in enumerate(rate_cols):\n",
        "  #   # Extract the name of the yield\n",
        "  #   name = 'Yield:'+re.findall(r'\\d+', rate)[0]+' Year'\n",
        "  #   fig.add_trace(go.Scatter(x=df.index, y=df[rate],name=name,line_color = colors[i]),row=2,col=1)\n",
        "\n",
        "  # stochastic oscillator\n",
        "  fig.add_trace(\n",
        "      go.Scatter(\n",
        "          name = 'stoch_K',\n",
        "          x = df.index,\n",
        "          y = df.stoch_K,\n",
        "          marker_color = 'blue'\n",
        "      ),row=2,col=1\n",
        "  )\n",
        "  fig.add_trace(\n",
        "      go.Scatter(\n",
        "          name = 'stoch_D',\n",
        "          x = df.index,\n",
        "          y = df.stoch_D,\n",
        "          marker_color = 'skyblue'\n",
        "      ),row=2,col=1\n",
        "  )\n",
        "\n",
        "  # # RSI\n",
        "  # ********************************************************************************************\n",
        "  fig.add_trace(go.Scatter(x=df.index,y=df['rsi'],name='RSI',line_color='#F00F3C'),row=2,col=2)\n",
        "  fig.add_shape(type ='rect',\n",
        "                x0=min(df.index),\n",
        "                x1=max(df.index),\n",
        "                y0=30.0,\n",
        "                y1=70.0,\n",
        "                line=dict(color='#F00F3C'),\n",
        "                fillcolor='#F00F3C',\n",
        "                opacity=0.1,\n",
        "                row=2,col=2)\n",
        "  fig.update_shapes(dict(xref='x',yref='y'),row=2,col=1)\n",
        "\n",
        "\n",
        "  # Set template\n",
        "  fig.update_layout(template = 'plotly_white',width= 1000,height=800,title ='Technical Indicators & Yields')\n",
        "  fig.show()\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2xM47BDgGyE"
      },
      "source": [
        "def plot_bbands(df,feature):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  fig = go.Figure()\n",
        "  fig.add_trace(go.Scatter(x=df.index,y=df[f'b-upper-{feature}'],name='Bollinger-Upper',line_color=\"#DFEBF9\"))\n",
        "  fig.add_trace(go.Scatter(x=df.index,y=df[f'b-lower-{feature}'],name='Bollinger-Lower',line_color='#DFEBF9',fill='tonexty'))\n",
        "  fig.add_trace(go.Scatter(x=df.index,y=df[feature],name=feature,line_color='#a8b8d0'))\n",
        "  fig.update_layout(template = 'plotly_white',width =700,height=500,title = f'{feature}-Bollinger Bands')\n",
        "  fig.show()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F0OYlkW7fkp"
      },
      "source": [
        "### Cypto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glK8ISeGWU9m"
      },
      "source": [
        "#### Crypto Prices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnXHLV8PRm_Y"
      },
      "source": [
        "def get_crypto_spot(ticker,from_,to_,interval='1d'):\n",
        "  \"\"\"\n",
        "  Get crypto spot rates from gate.io. Returns a dataframe of prices by date\n",
        "  Params:\n",
        "    ticker: crypto symbol\n",
        "    from_: date from\n",
        "    to_  : date to\n",
        "    interval: 1d\n",
        "  \"\"\"\n",
        "  # convert to unixtimestamp\n",
        "  f = int(time.mktime(time.strptime(from_, \"%Y-%m-%d\")))\n",
        "  t = int(time.mktime(time.strptime(to_, \"%Y-%m-%d\")))\n",
        "\n",
        "  # request headers\n",
        "  host = \"https://api.gateio.ws\"\n",
        "  prefix = \"/api/v4\"\n",
        "  headers = {'Accept': 'application/json', 'Content-Type': 'application/json'}\n",
        "  url = '/spot/candlesticks'\n",
        "  query_param = f'currency_pair={ticker}_USDT&from={f}&to={t}&interval={interval}'\n",
        "\n",
        "  # make request\n",
        "  r = requests.request('GET', host + prefix + url + \"?\" + query_param, headers=headers)\n",
        "\n",
        "  # if successful, convert to df,convert unixtimestamp, set the index & subset columns\n",
        "  if r.status_code == 200:\n",
        "    df = pd.DataFrame(r.json())\n",
        "    df.columns = ['time','volume','close','high','low','open']\n",
        "    df['date'] = df['time'].apply(lambda x:datetime.utcfromtimestamp(int(x)).strftime('%Y-%m-%d'))\n",
        "    df['ticker'] = ticker\n",
        "    df.set_index('date',inplace=True)\n",
        "    df = df[['ticker','open','high','low','close','volume']]\n",
        "    \n",
        "    # change data types\n",
        "    df.index = pd.to_datetime(df.index)\n",
        "\n",
        "    # convert datatype to float\n",
        "    for col in ['open','high','low','close','volume']:\n",
        "      df[col] = df[col].astype('float')\n",
        "  else:\n",
        "    df = pd.DataFrame()\n",
        "  \n",
        "  return df"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFTtutnYQOuj"
      },
      "source": [
        "def get_crypto_spots(ticker,from_,to_,interval='1d'):\n",
        "  \"\"\"\n",
        "  Make multiple requests to gate.io to get crypto prices (max 1,000 per request)\n",
        "  This function breaks the date range into multiple requests and consolidates \n",
        "  if needed\n",
        "  Params:\n",
        "    ticker: crypto symbol\n",
        "    from_ : date from as string\n",
        "    to_   : date to as string\n",
        "    interval: 1 day\n",
        "\n",
        "  https://www.gate.io/docs/developers/apiv4/en/#get-futures-candlesticks\n",
        "  \"\"\"\n",
        "\n",
        "  # calc the number of days in the requested range\n",
        "  # max data per request is 1,000\n",
        "  # multiple requests are needed if the delta is >1,000\n",
        "  to_   = datetime.strptime(to_, '%Y-%m-%d')\n",
        "  from_ = datetime.strptime(from_, '%Y-%m-%d')\n",
        "  delta = to_-from_\n",
        "  num_requests = delta.days/999\n",
        "\n",
        "  # split into multiple requests if needed\n",
        "  if num_requests >1:\n",
        "    for i,req in enumerate(range(delta.days//999)):\n",
        "      # first date range, create the first df\n",
        "      if i ==0:\n",
        "        # must adjust dates beween datetime objects\n",
        "        # and strings for processing\n",
        "        start = date(from_.year,from_.month,from_.day)\n",
        "        end = start+timedelta(days=999)\n",
        "        start_str = str(start)\n",
        "        end_str = str(date(end.year,end.month,end.day))\n",
        "\n",
        "        # request data\n",
        "        df = get_crypto_spot(ticker,start_str,end_str,interval)\n",
        "\n",
        "      else: #append to existing df\n",
        "        start = end + timedelta(days=1)\n",
        "        end = start + timedelta(days=999)\n",
        "        start_str = str(date(start.year,start.month,start.day))\n",
        "        end_str = str(date(end.year,end.month,end.day))\n",
        "\n",
        "        # make request, append results to df\n",
        "        df_tmp = get_crypto_spot(ticker,start_str,end_str,interval)\n",
        "        df = pd.concat([df,df_tmp])\n",
        "\n",
        "    # request the data for the remaining range\n",
        "    start = end + timedelta(days=1)\n",
        "    start_str = str(date(start.year,start.month,start.day))\n",
        "    end_str = str(date(to_.year,to_.month,to_.day))\n",
        "\n",
        "    # make request, append data to df\n",
        "    df_tmp = get_crypto_spot(ticker,start_str,end_str,interval)\n",
        "    df = pd.concat([df,df_tmp])\n",
        "\n",
        "  else:\n",
        "    # if only one request is needed (less than 1000 days in range)\n",
        "    start = str(date(from_.year,from_.month,from_.day))\n",
        "    end = str(date(to_.year,to_.month,to_.day))\n",
        "    df = get_crypto_spot(ticker,start,end,interval)\n",
        "\n",
        "\n",
        "  # Calculate missing data\n",
        "  missing = sum(df['close'].isna())\n",
        "  total = df.shape[0]\n",
        "  missing_pct = round(missing/total*100,2)\n",
        "\n",
        "  # Print the results\n",
        "  summary = ['Ticker',f'{ticker}-Spots',str(total),str(missing),str(missing_pct)+'%','none']\n",
        "\n",
        "  return {'summary':summary,'data':df}\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8GmSXuw_HLA"
      },
      "source": [
        "#### Crypto Futures\n",
        "+ https://www.cnbc.com/quotes/@BTC.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDt90dvGwRWN"
      },
      "source": [
        "def get_crypto_futures(ticker,from_,to_,interval='1d'):\n",
        "  \"\"\"\n",
        "  Get crypto futures prices from gate.io. Returns a dataframe with open,high,low,close, and volume\n",
        "  Params:\n",
        "    ticker: crypto symbol\n",
        "    from_: from date yyyy-mm-dd\n",
        "    to_  : to date yyyy-mm-dd\n",
        "    interval: 1d\n",
        "  https://www.gate.io/docs/developers/apiv4/en/#get-futures-candlesticks\n",
        "  \"\"\"\n",
        "\n",
        "  # request headers\n",
        "  host = \"https://api.gateio.ws\"\n",
        "  prefix = \"/api/v4\"\n",
        "  headers = {'Accept': 'application/json', 'Content-Type': 'application/json'}\n",
        "  url = '/futures/usdt/candlesticks'\n",
        "\n",
        "  # min date of futures is Nov 18,2019\n",
        "  from_ = max(from_,'2019-11-18')\n",
        "\n",
        "  # convert to unixtimestamp\n",
        "  f = time.mktime(time.strptime(from_, \"%Y-%m-%d\"))\n",
        "  t = time.mktime(time.strptime(to_, \"%Y-%m-%d\"))\n",
        "  query_param = f'contract={ticker}_USDT&interval={interval}&from={f}&to={t}'\n",
        "\n",
        "\n",
        "  # request the data\n",
        "  r = requests.request('GET', host + prefix + url + \"?\" + query_param, headers=headers)\n",
        "\n",
        "  # if successful, convert to df,convert unixtimestamp, set the index & subset columns\n",
        "  if r.status_code == 200:\n",
        "    df = pd.DataFrame(r.json())\n",
        "    df['date'] = df['t'].apply(lambda x:datetime.utcfromtimestamp(x).strftime('%Y-%m-%d'))\n",
        "    df.set_index('date',inplace=True)\n",
        "    df = df[['o','h','l','c','v']]\n",
        "    df.columns = ['futures_open','futures_high','futures_low','futures_close','futures_volume']\n",
        "\n",
        "    # change data types\n",
        "    df.index = pd.to_datetime(df.index)\n",
        "\n",
        "    # convert datatype to float\n",
        "    for col in ['futures_open','futures_high','futures_low','futures_close','futures_volume']:\n",
        "      df[col] = df[col].astype('float')\n",
        "\n",
        "    # Calculate missing data\n",
        "    missing = sum(df['futures_close'].isna())\n",
        "    total = df.shape[0]\n",
        "    missing_pct = round(missing/total*100,2)\n",
        "\n",
        "    # Print the results\n",
        "    summary = ['Ticker',f'{ticker}-Futures',str(total),str(missing),str(missing_pct)+'%','none']\n",
        "\n",
        "  else:\n",
        "    summary = ['Ticker',f'{ticker}-Futures',f'Error:{r.status_code}','all','100%','none']\n",
        "    df = pd.DataFrame()\n",
        "  \n",
        "  return {'summary':summary,'data':df}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyHMlqvZ_Eah"
      },
      "source": [
        "#### Fear and Greed Index for Bitcoin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEw-tzMz7ihc"
      },
      "source": [
        "def get_fear_greed_index(index_date = None):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  if index_date is None:\n",
        "    # get all data available\n",
        "    url =\"https://api.alternative.me/fng/?limit=0&date_format=cn\"\n",
        "  else:\n",
        "    # get the latest three data-points\n",
        "    url = \"https://api.alternative.me/fng/?limit=3&date_format=cn\"\n",
        "  \n",
        "  # make request\n",
        "  r = requests.get(url)\n",
        "\n",
        "  # check the status of the request \n",
        "  if r.status_code ==200:\n",
        "\n",
        "    # convert data to a dataframe\n",
        "    data = r.json()\n",
        "    df = pd.DataFrame(data['data'])\n",
        "    df['date'] = pd.to_datetime(df['timestamp'])\n",
        "    df.set_index('date',inplace=True)\n",
        "    df = df[['value','value_classification']]\n",
        "    df.columns = ['idx_fear_greed','idx_classification']\n",
        "\n",
        "    # convert datatype to float\n",
        "    df['idx_fear_greed'] = df['idx_fear_greed'].astype('float')\n",
        "\n",
        "    # Calculate missing data\n",
        "    missing = sum(df['idx_fear_greed'].isna())\n",
        "    total = df.shape[0]\n",
        "    missing_pct = round(missing/total*100,2)\n",
        "\n",
        "    if index_date is not None:\n",
        "      # filter for the index date\n",
        "      df = df[index_date]\n",
        "\n",
        "    # Print the results\n",
        "    summary = ['Ticker','Fear-Greed-Index',str(total),str(missing),str(missing_pct)+'%','none']\n",
        "\n",
        "  else: #request error\n",
        "      summary = ['Ticker','Fear-Greed-Index','Request Error','all','100%','none']\n",
        "      df = pd.DataFrame()\n",
        "\n",
        "  return {'summary':summary,'data':df}"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px4S3dogD7ND"
      },
      "source": [
        "#### Google Trends"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYXC7i33D28L"
      },
      "source": [
        "def get_google_trends(search_terms_list,timeframe ='today 5-y' ):\n",
        "  \"\"\"\n",
        "  Get search term frequency from google\n",
        "  Params:\n",
        "    search_terms: list of google search terms (max 5)\n",
        "    timeframe: 'today 5-y', '2016-12-14 2017-01-25'\n",
        "  Reference: https://pypi.org/project/pytrends/\n",
        "  \"\"\"\n",
        "  # connect to google trends\n",
        "  pytrends = TrendReq(hl='en-US', tz=360)\n",
        "\n",
        "  # search for the terms\n",
        "  pytrends.build_payload(search_terms_list,timeframe=timeframe)\n",
        "\n",
        "  # get data over time\n",
        "  df = pytrends.interest_over_time()\n",
        "\n",
        "  df.columns = ['google_trends','isPartial']\n",
        "  df = df[['google_trends']]\n",
        "\n",
        "  # Calculate missing data\n",
        "  missing = sum(df['google_trends'].isna())\n",
        "  total = df.shape[0]\n",
        "  missing_pct = round(missing/total*100,2)\n",
        "\n",
        "  # Print the results\n",
        "  summary = ['Ticker',f'Google Trends',str(total),str(missing),str(missing_pct)+'%','none']\n",
        "\n",
        "  return {'summary':summary,'data':df}"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxrMbD4g-Ai0"
      },
      "source": [
        "# Get Consolidated Crypto Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nhAeAUN9KLi"
      },
      "source": [
        "#### Data Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7oR0KUUXl4g"
      },
      "source": [
        "ticker = 'BTC'\n",
        "search_terms = ['how to buy bitcoin']\n",
        "path = f'/content/drive/MyDrive/Colab Notebooks/capstone2/data/'\n",
        "\n",
        "config_crypto = {\n",
        "    'process':True,\n",
        "    'data':{'spot':ticker,'futures':ticker,'index':'fear_greed_index'}\n",
        "}\n",
        "config_commodities = {\n",
        "    'process':True,\n",
        "    'data':['GLD','OIL','BOIL','VXX','SPY','XLE','QQQ']\n",
        "    }\n",
        "config_technicals = {\n",
        "    'process':True,\n",
        "    'data':[{'name':'bbands','window':20,'stdev':2},{'name':'rsi','window':14},{'name':'stoch','window':14},{'name':'macd','long':26,'short':12,'ma':9}]\n",
        "}     \n",
        "config_sentiment = {\n",
        "    'process':True,\n",
        "    'data':[{'name':'news','path':f'{path}{ticker}_sentiment.pickle'},{'name':'news_volume','path':f'{path}{ticker}_news_counts.pickle'},{'name':'google_trends','search_terms':search_terms}]\n",
        "}\n",
        "config_fx = {\n",
        "    'process':True,\n",
        "    'data':[{'from':'USD','to':'EUR'},{'from':'USD','to':'JPY'},{'from':'USD','to':'GBP'}]\n",
        "}\n",
        "config_econ = {\n",
        "    'process':True,\n",
        "    'data':{'TREASURY_YIELD':[{'interval':'daily','maturity':'5year','name':'yield5y'},\n",
        "                            {'interval':'daily','maturity':'10year','name':'yield10y'},\n",
        "                            {'interval':'daily','maturity':'30year','name':'yield30y'},\n",
        "                            {'interval':'daily','maturity':'3month','name':'yield3m'}\n",
        "                            ],\n",
        "          'FEDERAL_FUNDS_RATE':{'interval':'daily','name':'ir'},\n",
        "          'NONFARM_PAYROLL':{'interval':'monthly','name':'nfp'},\n",
        "          'REAL_GDP':{'interval':'quarterly','name':'gdp'},\n",
        "          'UNEMPLOYMENT':{'interval':'monthly','name':'unemployment'},\n",
        "          'CONSUMER_SENTIMENT':{'interval':'monthly','name':'cs'},\n",
        "          'INFLATION_EXPECTATION':{'interval':'monthly','name':'infl'},  \n",
        "  }\n",
        "}\n",
        "\n",
        "# combine\n",
        "config = {'Crypto':config_crypto,\n",
        "          'Commodities':config_commodities,\n",
        "          'Technical':config_technicals,\n",
        "          'Sentiment':config_sentiment,\n",
        "          'FX':config_fx,\n",
        "          'Economic':config_econ\n",
        "          }"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKLT19L0lS8m"
      },
      "source": [
        "def get_consolidated_data(config,key,from_,to_,interval='1d',throttle=30,dropna=False):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "\n",
        "  # Result header and accumulator\n",
        "  header = ['Type','Data','Total','Missing',' % ','Action']\n",
        "  summary =[]\n",
        "\n",
        "\n",
        "  # get spot crypto data, add month/weekday cols\n",
        "  # ****************************************************************************\n",
        "  # get spot crypto prices\n",
        "  if config['Crypto']['process']:\n",
        "    try:\n",
        "      results = get_crypto_spots(config['Crypto']['data']['spot'],from_,to_,interval)\n",
        "      dff = results['data']\n",
        "      dff['month'] =dff.index.month\n",
        "      dff['weekday']=dff.index.weekday\n",
        "      summary.append(results['summary'])\n",
        "      print(f\"Complete:===>Spot Crypto:{config['Crypto']['data']['spot']}\")\n",
        "    except:\n",
        "      print(f\"Error:=====>Spot Crypto:{config['Crypto']['data']['spot']}\")\n",
        "      return ''\n",
        "\n",
        "  # get futures prices\n",
        "  # ****************************************************************************\n",
        "  if config['Crypto']['process']:\n",
        "    try:\n",
        "      # get data between from and to\n",
        "      # earliest date available is nov 18, 2019\n",
        "      results = get_crypto_futures(config['Crypto']['data']['futures'],from_,to_,interval)\n",
        "\n",
        "      # append results\n",
        "      summary.append(results['summary'])\n",
        "      dff = dff.join(results['data'],how='left')\n",
        "\n",
        "      print(f\"Complete:===>Futures Crypto:{config['Crypto']['data']['futures']}\")\n",
        "    except:\n",
        "      print(f\"Error:=====>Futures Crypto:{config['Crypto']['data']['futures']}\")\n",
        "    \n",
        "    # get bitcoin index\n",
        "    # **************************************************************************\n",
        "    if config['Crypto']['process']:\n",
        "      try:\n",
        "        results = get_fear_greed_index()\n",
        "\n",
        "        #append the results\n",
        "        summary.append(results['summary'])\n",
        "        dff = dff.join(results['data'],how='left')\n",
        "        print('Complete:===>Fear-Greed Index')\n",
        "      except:\n",
        "        print('Error:=====>Fear-Greed Index')\n",
        "\n",
        "  # Sentiment\n",
        "  # ****************************************************************************\n",
        "  if config['Sentiment']['process']:\n",
        "    for sent in config['Sentiment']['data']:\n",
        "      if sent['name']=='google_trends' and len(sent['search_terms'])>=1:\n",
        "        try:\n",
        "          results = get_google_trends(sent['search_terms'])\n",
        "\n",
        "          # update the action log\n",
        "          if results['summary'][5]=='none':\n",
        "            # there were no missing values to interpolate\n",
        "            results['summary'][5]=f\"fill weekly to daily\"\n",
        "          else:\n",
        "            # missing values were interpolated\n",
        "            results['summary'][5]=f\"{results['summary'][5]} + fill weekly to daily\"\n",
        "      \n",
        "          # fill in missing days (measured weekly)\n",
        "          df = results['data']\n",
        "          days = pd.date_range(start = min(df.index),end =max(dff.index),freq='D')\n",
        "          df =df.reindex(days,method = 'bfill')\n",
        "\n",
        "          # join with main df\n",
        "          dff = dff.join(df,how='left')\n",
        "          summary.append(results['summary'])\n",
        "\n",
        "          # calc bbands for google trend data\n",
        "          calc_bollinger(dff,'google_trends')\n",
        "          print('Complete:===>Google Trends Data')\n",
        "\n",
        "        except:\n",
        "          print('Error:=====>Google Trends Data')\n",
        "\n",
        "      if sent['name']=='news' and sent['path'] is not None:\n",
        "        df_news = pd.read_pickle(sent['path'])\n",
        "        dff =dff.join(df_news,how='left')\n",
        "\n",
        "        # Calc bbands for sentiment moving average line\n",
        "        calc_bollinger(dff,'ma_sentiment_10')\n",
        "        print(\"Complete:===>News Sentiment\")\n",
        "\n",
        "      if sent['name']=='news_volume' and sent['path'] is not None:\n",
        "        df_news = pd.read_pickle(sent['path'])\n",
        "        dff =dff.join(df_news,how='left')\n",
        "\n",
        "        # calc bands for news volume and title sentiment\n",
        "        calc_bollinger(dff,'ma_news_count')\n",
        "        calc_bollinger(dff,'ma_sentiment_title')\n",
        "        print('Complete:===>News Count')\n",
        "\n",
        "  # FX rates\n",
        "  # ****************************************************************************\n",
        "  if config['FX']['process']:\n",
        "    for fx in config['FX']['data']:\n",
        "      try:\n",
        "        results = get_fx_rates(fx['from'],fx['to'],key)\n",
        "        df = results['data']\n",
        "        summary.append(results['summary'])\n",
        "        dff = dff.join(df,how='left')\n",
        "        print(f\"Complete:===>FX:{fx['from']}->{fx['to']}\")\n",
        "      except:\n",
        "        summary.append(results['summary'])\n",
        "        print(f\"Error:=====>FX:{fx['from']}->{fx['to']}\")\n",
        "\n",
        "  # Get Commodity prices\n",
        "  # ****************************************************************************\n",
        "  if config['Commodities']['process']:\n",
        "    for commodity in config['Commodities']['data']:\n",
        "      try:\n",
        "        # get prices\n",
        "        results = get_ticker_data(commodity,key,'full',throttle)\n",
        "        df = results['data']\n",
        "        summary.append(results['summary'])\n",
        "        print(f'Complete:===>Commodity:{commodity}')\n",
        "\n",
        "        # rename close to commodity name, remove unneeded columns and join with \n",
        "        # the crypto prices by date\n",
        "        df.rename(columns={'close':commodity},inplace=True)\n",
        "        df.drop(['open','high','low','volume','symbol'],axis=1,inplace=True)\n",
        "        dff = dff.join(df,how='left')\n",
        "      except:\n",
        "        print(f\"Error:=====>Commodity:{commodity}\")\n",
        "    \n",
        "  # Technical Indicators\n",
        "  # ****************************************************************************\n",
        "  if config['Technical']['process']:\n",
        "    for tech in config['Technical']['data']:\n",
        "      if tech['name']=='bbands':\n",
        "        calc_bollinger(dff,'close',tech['window'],tech['stdev'])\n",
        "        print('Complete:===>Bollinger Bands Calculated')\n",
        "      elif tech['name']=='rsi':\n",
        "        calc_rsi(dff,'close',tech['window'])\n",
        "        print('Complete:===>RSI Calculated')\n",
        "      elif tech['name']=='macd':\n",
        "        calc_macd(dff,tech['long'],tech['short'],tech['ma'])\n",
        "        print('Complete:===>MACD Calculated')\n",
        "      elif tech['name']=='stoch':\n",
        "        calc_stoch_ossilator(dff,tech['window'])\n",
        "        print('Complete:===>Stochastic Oscillator Calculated')\n",
        "      else:\n",
        "        print('')\n",
        "\n",
        "  # Economic Indicators\n",
        "  # ****************************************************************************\n",
        "  # loop through the config to pull the requested data\n",
        "  if config['Economic']['process']:\n",
        "    for indicator,values in config['Economic']['data'].items():\n",
        "      if indicator == 'TREASURY_YIELD':\n",
        "        for tr in values:\n",
        "          try:\n",
        "            # treasury yields have a maturity component\n",
        "            results = get_economic_indicators(indicator,key,interval=tr['interval'],maturity=tr['maturity'],throttle=throttle)\n",
        "            summary.append(results['summary'])\n",
        "\n",
        "            # extract the data, rename columns\n",
        "            df = results['data']\n",
        "            df.rename(columns={\"value\": tr['name']},inplace=True)\n",
        "            df.drop(['name', 'interval'], axis=1,inplace = True)\n",
        "\n",
        "            # append to consolidated dff\n",
        "            dff = dff.join(df,how='left')\n",
        "            print(f\"Complete:===>{indicator}:{tr['maturity']}\")\n",
        "\n",
        "          except:\n",
        "            print(f\"Error:=====>{indicator}:{tr['maturity']}\")\n",
        "    \n",
        "      else: \n",
        "        # daily\n",
        "        if values['interval']=='daily':\n",
        "          try:\n",
        "            results = get_economic_indicators(indicator,key,interval=values['interval'],throttle=throttle)\n",
        "            df = results['data']\n",
        "            summary.append(results['summary'])\n",
        "            \n",
        "            df.rename(columns={\"value\": values['name']},inplace=True)\n",
        "            df.drop(['name', 'interval'], axis=1,inplace = True)\n",
        "            dff = dff.join(df,how='left')\n",
        "            print(f\"Complete:===>{indicator}\")\n",
        "          except:\n",
        "            print(f\"Error:=====>{indicator}\")\n",
        "    \n",
        "        else: \n",
        "          try:\n",
        "            # weekly, monthly or quarterly\n",
        "            results =get_economic_indicators(indicator,key,interval=values['interval'],throttle=throttle)\n",
        "            df = results['data']\n",
        "            \n",
        "            # reindex to daily, fill missing values forward (index is in reverse order)\n",
        "            days = pd.date_range(start = min(df.index),end =max(dff.index),freq='D')\n",
        "            df =df.reindex(days,method = 'bfill')\n",
        "\n",
        "            # update the action log\n",
        "            if results['summary'][5]=='none':\n",
        "              # there were no missing values to interpolate\n",
        "              results['summary'][5]=f\"fill {values['interval']} to daily\"\n",
        "            else:\n",
        "              # missing values were interpolated\n",
        "              results['summary'][5]=f\"{results['summary'][5]} + fill {values['interval']} to daily\"\n",
        "\n",
        "            summary.append(results['summary'])\n",
        "        \n",
        "            # join with the other data\n",
        "            df.rename(columns={\"value\": values['name']},inplace=True)\n",
        "            df.drop(['name', 'interval'], axis=1,inplace = True)\n",
        "            dff = dff.join(df,how='left')\n",
        "            print(f\"Complete:===>{indicator}\")\n",
        "          except:\n",
        "            print(f\"Error:=====>{indicator}\")\n",
        "\n",
        "\n",
        "  # Fill in any missing data after joining all datasets\n",
        "  dff.fillna(method='ffill',inplace=True,axis = 0)\n",
        "\n",
        "  # drop rows with missing commodity prices\n",
        "  if dropna:\n",
        "    dff.dropna(how='any',inplace=True)\n",
        "\n",
        "  # print the results table\n",
        "  print(\"\\n\\n\")\n",
        "  print(tabulate(summary,header))\n",
        "\n",
        "  return dff\n",
        "  "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGlp803y_KZ5",
        "outputId": "6450cbd2-c3c5-41fb-82cc-94b285c3ae93"
      },
      "source": [
        "\n",
        "# get the consolidated data\n",
        "df =get_consolidated_data(config,key,'2016-01-01','2021-10-25')\n",
        "\n",
        "# save to google drive\n",
        "df.to_pickle(f'{path}{ticker}_market_data.pickle')\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complete:===>Spot Crypto:BTC\n",
            "Complete:===>Futures Crypto:BTC\n",
            "Complete:===>Fear-Greed Index\n",
            "Complete:===>News Sentiment\n",
            "Complete:===>News Count\n",
            "Complete:===>Google Trends Data\n",
            "Complete:===>FX:USD->EUR\n",
            "Complete:===>FX:USD->JPY\n",
            "Complete:===>FX:USD->GBP\n",
            "Complete:===>Commodity:GLD\n",
            "Complete:===>Commodity:OIL\n",
            "Complete:===>Commodity:BOIL\n",
            "Complete:===>Commodity:VXX\n",
            "Complete:===>Commodity:SPY\n",
            "Complete:===>Commodity:XLE\n",
            "Complete:===>Commodity:QQQ\n",
            "Complete:===>Bollinger Bands Calculated\n",
            "Complete:===>RSI Calculated\n",
            "Complete:===>Stochastic Oscillator Calculated\n",
            "Complete:===>MACD Calculated\n",
            "Complete:===>TREASURY_YIELD:5year\n",
            "Complete:===>TREASURY_YIELD:10year\n",
            "Complete:===>TREASURY_YIELD:30year\n",
            "Complete:===>TREASURY_YIELD:3month\n",
            "Complete:===>FEDERAL_FUNDS_RATE\n",
            "Complete:===>NONFARM_PAYROLL\n",
            "Complete:===>REAL_GDP\n",
            "Complete:===>UNEMPLOYMENT\n",
            "Complete:===>CONSUMER_SENTIMENT\n",
            "Complete:===>INFLATION_EXPECTATION\n",
            "\n",
            "\n",
            "\n",
            "Type                Data                     Total    Missing   %      Action\n",
            "------------------  ---------------------  -------  ---------  ------  -------------------------------------------\n",
            "Ticker              BTC-Spots                 2125          0  0.0%    none\n",
            "Ticker              BTC-Futures                708          0  0.0%    none\n",
            "Ticker              Fear-Greed-Index          1362          0  0.0%    none\n",
            "Ticker              Google Trends              261          0  0.0%    fill weekly to daily\n",
            "Ticker              USD/EUR                   1818          0  0.0%    none\n",
            "Ticker              USD/JPY                   5000          0  0.0%    none\n",
            "Ticker              USD/GBP                   1818          0  0.0%    none\n",
            "Ticker              GLD                       4264          0  0.0%    none\n",
            "Ticker              OIL                       2647          0  0.0%    none\n",
            "Ticker              BOIL                      2531          0  0.0%    none\n",
            "Ticker              VXX                       3208          0  0.0%    none\n",
            "Ticker              SPY                       5533          0  0.0%    none\n",
            "Ticker              XLE                       5533          0  0.0%    none\n",
            "Ticker              QQQ                       5533          0  0.0%    none\n",
            "Economic Indicator  TREASURY_YIELD:5year     15605        665  4.26%   interpolate-missing\n",
            "Economic Indicator  TREASURY_YIELD:10year    15605        665  4.26%   interpolate-missing\n",
            "Economic Indicator  TREASURY_YIELD:30year    11660        490  4.2%    interpolate-missing\n",
            "Economic Indicator  TREASURY_YIELD:3month    10475        437  4.17%   interpolate-missing\n",
            "Economic Indicator  FEDERAL_FUNDS_RATE       24589          0  0.0%    none\n",
            "Economic Indicator  NONFARM_PAYROLL            993          0  0.0%    fill monthly to daily\n",
            "Economic Indicator  REAL_GDP                    78          0  0.0%    fill quarterly to daily\n",
            "Economic Indicator  UNEMPLOYMENT               885          0  0.0%    fill monthly to daily\n",
            "Economic Indicator  CONSUMER_SENTIMENT         826        210  25.42%  interpolate-missing + fill monthly to daily\n",
            "Economic Indicator  INFLATION_EXPECTATION      524          0  0.0%    fill monthly to daily\n"
          ]
        }
      ]
    }
  ]
}